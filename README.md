# Visi√≥n Computacional - Implementaci√≥n de rob√≥tica inteligente

Retos de visi√≥n computacional desarrollados para el curso "Implementaci√≥n de rob√≥tica inteligente."

## Canny Edge Detection

<code>Canny2/Canny_EdgeVideo.py</code> carga un v√≠deo y aplica detecci√≥n de bordes de **Canny** junto a un filtro de **Kalman** para resaltar y seguir los centroides de los contornos.

### ¬øC√≥mo funciona?

1. **Extracci√≥n de contornos**  
   Cada fotograma se convierte a escala de grises y se aplica Canny para obtener un mapa de bordes.  
2. **C√°lculo de centroides**  
   A partir de los momentos de imagen, se determina el centroide de cada contorno detectado.  
3. **Filtro de Kalman**  
   - El primer centroide inicializa el estado del filtro.  
   - Cada medici√≥n posterior (nuevo centroide) se utiliza para predecir y corregir la posici√≥n estimada, suavizando las oscilaciones.  
4. **Visualizaci√≥n**  
   Se superpone el mapa de bordes sobre el fotograma en gris, dibujando cada contorno y marcando su centroide con un punto blanco.

### Uso

Coloca un v√≠deo de ejemplo <code>video.mp4</code> en la carpeta <code>Canny2</code>, navega hasta ella y ejecuta:

```bash
python3 Canny_EdgeVideo.py
```
<p align="center">
  <img src="https://github.com/user-attachments/assets/2443e45b-8fff-40ce-a46f-21987da4b759" alt="Canny Edge Detection Demo" width="600"/>
</p>




# ü§ñ Control de NiryoOne en CoppeliaSim con Python, MediaPipe y ZeroMQ API

Este proyecto permite controlar el brazo rob√≥tico NiryoOne en CoppeliaSim usando los movimientos de tu brazo capturados por webcam y MediaPipe. Adem√°s, puedes controlar la pinza para agarrar objetos virtuales. Todo se comunica usando la moderna ZeroMQ Remote API.

## üõ†Ô∏è T√©cnicas y Tecnolog√≠as Usadas

- **MediaPipe (Pose & Hands)**:  
  Para detectar y rastrear en tiempo real los puntos clave del brazo y la mano usando la webcam.
- **OpenCV**:  
  Para la captura y visualizaci√≥n de video.
- **ZeroMQ Remote API**:  
  Comunicaci√≥n moderna y eficiente entre Python y CoppeliaSim.
- **CoppeliaSim (V-REP)**:  
  Simulaci√≥n f√≠sica y visual del robot NiryoOne.
- **Lua Scripting**:  
  Control directo de la pinza (gripper) dentro de la simulaci√≥n.
- **Kinematics Addon**:  
  Para la cinem√°tica inversa (IK) del robot, ya que la versi√≥n usada de CoppeliaSim no tiene soporte nativo de IK Groups.

## ‚ö° Implementaci√≥n del ZeroMQ Remote API

- Se elimin√≥ todo el c√≥digo legado (`simx*`) y se migr√≥ completamente a la API ZeroMQ:
  ```python
  from coppeliasim_zmqremoteapi_client import RemoteAPIClient
  client = RemoteAPIClient()
  sim = client.require('sim')
  ```
- Todos los objetos y se√±ales se manejan usando los m√©todos modernos de la API (`getObject`, `setObjectPosition`, `setFloatSignal`, etc).

## üèóÔ∏è Cambios y Configuraci√≥n en CoppeliaSim

### 1. **Renombrar Objetos y Estructura**
- Se aseguraron los siguientes nombres (¬°importante!):
  - `/NiryoOne/NiryoOne_target` (dummy para el target IK)
  - `/NiryoOne/NiryoOne_tip` (dummy para el tip IK)
  - `/NiryoOne/NiryoOne_joint1` ... `/NiryoOne/NiryoOne_joint6` (joints del robot)
  - `/NiryoOne/NiryoOneGripper` (pinza)
  - `/NiryoOne/NiryoOneGripper/leftJoint1` y `/rightJoint1` (joints de los dedos)

### 2. **Configuraci√≥n de Cinem√°tica Inversa (IK)**
- Se crearon los dummies `tip` y `target` y se colocaron correctamente en la jerarqu√≠a del robot.
- Se us√≥ el **Kinematics Addon** para crear y configurar el grupo IK, ya que la versi√≥n de CoppeliaSim no tiene soporte nativo.
- El script Python crea y resuelve el grupo IK en cada ciclo para mover el brazo seg√∫n la posici√≥n de la mu√±eca detectada.

### 3. **Script Lua para la Pinza ü¶æ**
- Se a√±adi√≥ un script Lua como child script en el objeto `NiryoOneGripper`:
  ```lua
  function sysCall_init()
      leftFinger = sim.getObject('../leftJoint1')
      rightFinger = sim.getObject('../rightJoint1')
      minPos = 0
      maxPos = 0.02
  end

  function sysCall_actuation()
      local opening = sim.getFloatSignal('gripper_opening')
      if opening ~= nil then
          local pos = minPos + (maxPos - minPos) * opening
          sim.setJointTargetPosition(leftFinger, pos)
          sim.setJointTargetPosition(rightFinger, pos)
      end
  end
  ```
- El script recibe la se√±al `gripper_opening` desde Python y ajusta la apertura de la pinza en tiempo real.

## üß† L√≥gica de Control (Python)

- **MediaPipe** detecta hombro, codo, mu√±eca, pulgar e √≠ndice.
- Se mapean las coordenadas 2D de la c√°mara a 3D en el espacio de CoppeliaSim.
- Solo la posici√≥n de la mu√±eca (wrist) actualiza el target IK para movimientos m√°s naturales.
- La distancia entre pulgar e √≠ndice controla la apertura de la pinza.

## üìù Notas y Consejos

- Ajusta los factores de escala y profundidad en el script Python para que el movimiento sea m√°s natural seg√∫n tu c√°mara y escena.
- Aseg√∫rate de que los nombres de los objetos en CoppeliaSim coincidan exactamente con los usados en el script.
- Si el robot no se mueve correctamente, revisa la configuraci√≥n del grupo IK y la jerarqu√≠a de los dummies.

## üöÄ ¬°Listo para usar!

1. Abre CoppeliaSim y carga la escena con el NiryoOne y los objetos renombrados.
2. Ejecuta el script Python.


# üè∫ Reconstrucci√≥n 3D de Figurilla Maya a partir de Video

Este proyecto permite reconstruir una nube de puntos 3D de una figurilla maya usando t√©cnicas de Structure from Motion (SfM) a partir de un video que recorre varios √°ngulos del objeto.

---

## üöÄ Tecnolog√≠as utilizadas

- **Python 3**
- **OpenCV** ‚Äì Detecci√≥n de caracter√≠sticas, extracci√≥n de frames, visualizaci√≥n de matches
- **Open3D** ‚Äì Visualizaci√≥n y manejo de nubes de puntos
- **NumPy** ‚Äì Procesamiento num√©rico
- **Matplotlib** ‚Äì Gr√°ficas comparativas de par√°metros
- **scikit-learn** ‚Äì Ajuste de par√°metros y optimizaci√≥n
- **SciPy** ‚Äì Optimizaci√≥n de nubes de puntos

---

## üìÇ Descripci√≥n de scripts

- **`sacar_fps.py`**
  - Extrae frames del video original, asegurando buena cobertura angular y calidad de imagen.
- **`deteccion_limites.py`**
  - Contiene la clase principal `SfMReconstructor` que realiza:
    - Detecci√≥n de caracter√≠sticas (SIFT/ORB)
    - Emparejamiento de puntos clave entre im√°genes
    - Pruebas autom√°ticas de par√°metros RANSAC
    - Reconstrucci√≥n 3D inicial y adici√≥n de vistas
    - Bundle adjustment y exportaci√≥n a `.ply`
- **`implementaci√≥n_bici.py`**
  - Script principal para ejecutar todo el pipeline de reconstrucci√≥n 3D.
- **`ver_nube.py`**
  - Visualiza la nube de puntos 3D generada (`.ply`) usando Open3D.
  - Permite limpiar, downsamplear y comparar nubes inicial/final.

---

## üñºÔ∏è Ejemplo de resultados

### Nube de puntos 3D reconstruida

<p align="center">
  <!-- Inserta aqu√≠ tu gif de la nube de puntos -->
  <img src="[ruta/a/tu_gif_nube.gif](https://github.com/user-attachments/assets/d89afcfa-6e5d-460a-9fec-ee6ef79ff168)" width="500"/>
</p>

### Ejemplo de matches y keypoints entre im√°genes

<p align="center">
  <!-- Inserta aqu√≠ tus im√°genes de matches -->
  <img src="https://github.com/user-attachments/assets/5a01a0d6-894d-4eef-8989-6820f376793d" width="300"/>
  <img src="https://github.com/user-attachments/assets/7575708c-629f-4130-a5c4-6bc19d6af6a7" width="300"/>
</p>

---

## üìù Pasos de uso

1. **Extrae los frames del video**
   ```bash
   python sacar_fps.py
   ```
2. **Ejecuta la reconstrucci√≥n 3D**
   ```bash
   python implementaci√≥n_bici.py
   ```
3. **Visualiza la nube de puntos**
   ```bash
   python ver_nube.py
   ```

---

## üìå Notas y recomendaciones

- Usa videos con buena iluminaci√≥n y fondo neutro para mejores resultados.
- Puedes ajustar los par√°metros de detecci√≥n y matching en `deteccion_limites.py`.
- Si la nube de puntos es pobre, prueba recortar las im√°genes o usar menos frames.

---
